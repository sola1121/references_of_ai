推荐引擎
推荐引擎是一个能预测用户兴趣点的模型.
推荐引擎通过协同过滤(collaborative filtering)或基于内容的过滤(content-based filtering)来产生一组推荐.
两种过滤方法的不同之处在于挖掘推荐的方式.
协同过滤从当前用户过去的行为和其他用户对当前用户的评分来构建模型, 然后使用这个模型来预测这个用户可能感兴趣的内容
基于内容的过滤用商品本身的特征来给用户推荐更多的商品, 商品间的相似度是模型主要的关注点.

from sklearn.ensemble import RandomForestClassifier    # 使用随机深林分类器增强
from sklearn.feature_selection import SelectKBest, f_regression   # 特征选择, 使用单变量线性回归测试
from sklearn.pipeline import Pipeline

# 特征选择器, 选择k个最好的特征, 这里k为10
selector_k_best = SelectKBest(score_func=f_regression, k=10)

# 随机森林分类器
classifier = RandomForestClassifier(n_estimators=50, max_depth=4)

# 构建机器学习流水线, 以输入顺序执行, 并为每一步指定一个名称
pipeline_classifier = Pipeline([("selector", selector_k_best), ("rf", classifier)])

选择k个最好的特征, 其好处在于可以处理较小维度的数据, 这对减小计算复杂度来说非常有用.
选择k个最佳特征的方式是基于单变量的特征的选择, 选择过程是先进行单变量统计测试, 然后从特征向量中抽取最优秀的特征.
单变量统计测试是指涉及一个变量的分析技术.
做了这些测试后, 向量空间中的每个特征将有一个评价分数.
基于这些评价分数, 选择最好的k个特征. 在分类器流水线中执行这个预处理步骤.
一旦抽取出k个特征, 一个k维的特征向量就形成了, 可以将这个特征向量用于随机森林分类器的输入训练数据.

为了构建一个推荐引擎, 需要定义相似度指标, 以便找到与数据库中特定用户相似的用户.
欧氏距离分数就是这样一个指标, 可计算两个数据点之间的欧几里得距离.
在数学中，欧几里得距离是欧几里得空间中两点间“普通”（即直线）距离。使用这个距离，欧氏空间成为度量空间。相关联的范数称为欧几里得范数。

皮尔逊积矩相关系数Pearson product-moment correlation coefficient, 又称作 PPMCC或PCCs. 
用于度量两个变量X和Y之间的相关（线性相关），其值介于-1与1之间。在自然科学领域中，该系数广泛用于度量两个变量之间的相关程度。
它是由卡尔·皮尔逊从弗朗西斯·高尔顿在19世纪80年代提出的一个相似却又稍有不同的想法演变而来。
这个相关系数也称作“皮尔森相关系数r”。

皮尔逊相关系数的变化范围为-1到1。 
系数的值为1意味着X 和 Y可以很好的由直线方程来描述，所有的数据点都很好的落在一条 直线上，且 Y 随着 X 的增加而增加。
系数的值为−1意味着所有的数据点都落在直线上，且 Y 随着 X 的增加而减少。
系数的值为0意味着两个变量之间没有线性关系。
更一般的, 我们发现，当且仅当 Xi and Yi 均落在他们各自的均值的同一侧， 则(Xi − X)(Yi − Y) 的值为正。 
也就是说，如果Xi 和 Yi 同时趋向于大于, 或同时趋向于小于他们各自的均值，则相关系数为正。 
如果 Xi 和 Yi 趋向于落在他们均值的相反一侧，则相关系数为负。